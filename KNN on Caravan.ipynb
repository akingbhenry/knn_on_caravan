{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bff2424f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba133939",
   "metadata": {},
   "source": [
    "### Importance of Scaling Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d956ad92",
   "metadata": {},
   "source": [
    "Let us first generate $20$ instances where each instance is two-dimensional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8d918ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2)\n",
    "points = np.random.normal(0, 1, size=(2, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e533bb5c",
   "metadata": {},
   "source": [
    "If we plot them, we will have the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df22a250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(points[0], points[1])\n",
    "plt.plot(points[0][:2], points[1][:2], 'ro-')\n",
    "plt.xlabel(r'$X_1$', fontsize=15)\n",
    "plt.ylabel(r'$X_2$', fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db05af4",
   "metadata": {},
   "source": [
    "Above, we have also connected two points with a line. We can see that these points are quite close to each other. Their distances in both directions are relatively close to each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6378f7c4",
   "metadata": {},
   "source": [
    "Now, let us multiply the $x_2$ value of each point by $10$. This is equivalent to increasing the scale of the second variable. Obviously, we have not lost any information, because the original $x_2$ value can always be retrieved by dividing the new value by $10$. So, we would hope that the result of any machine learning method would not change after such a re-scaling. However, in distance-based methods (such as KNN), this is not the case. Let us see the reason next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5749231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(points[0], 10*points[1])\n",
    "plt.plot(points[0][:2], 10*points[1][:2], 'ro-')\n",
    "plt.xlabel(r'$X_1$', fontsize=15)\n",
    "plt.ylabel(r'$X_2*10$', fontsize=15)\n",
    "plt.xlim([-30, 30])\n",
    "plt.ylim([-30, 30])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864f2431",
   "metadata": {},
   "source": [
    "As you can see, the distance is dominated by the vertical axis, and now the horizontal axis looks less important. This happened only by multiplying $x_2$ by $10$. Now think about a dataset of patient records, where some variables are some cell values between $10^{-4}$ to $10^{-6}$ and some other variables such as the age of a person can vary anywhere between $1$ to $120$. In this case all the distance will be dominated by the age, and our KNN method will just compare the ages of patients before deciding anything. Not very useful! We should keep this in mind now before starting with a KNN application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4041feb6",
   "metadata": {},
   "source": [
    "### KNN on the `Caravan` Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3bc893",
   "metadata": {},
   "source": [
    "We use the `Caravan` dataset from the `ISLR` library. The explanation of the dataset can be found [here](https://cran.r-project.org/web/packages/ISLR/ISLR.pdf) and we download the csv file from [this GitHub repository](https://github.com/JWarmenhoven/ISLR-python)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c2f752d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/JWarmenhoven/ISLR-python/master/Notebooks/Data/Caravan.csv\")\n",
    "df = df.drop(columns=df.columns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6cb2757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MOSTYPE</th>\n",
       "      <th>MAANTHUI</th>\n",
       "      <th>MGEMOMV</th>\n",
       "      <th>MGEMLEEF</th>\n",
       "      <th>MOSHOOFD</th>\n",
       "      <th>MGODRK</th>\n",
       "      <th>MGODPR</th>\n",
       "      <th>MGODOV</th>\n",
       "      <th>MGODGE</th>\n",
       "      <th>MRELGE</th>\n",
       "      <th>...</th>\n",
       "      <th>APERSONG</th>\n",
       "      <th>AGEZONG</th>\n",
       "      <th>AWAOREG</th>\n",
       "      <th>ABRAND</th>\n",
       "      <th>AZEILPL</th>\n",
       "      <th>APLEZIER</th>\n",
       "      <th>AFIETS</th>\n",
       "      <th>AINBOED</th>\n",
       "      <th>ABYSTAND</th>\n",
       "      <th>Purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MOSTYPE  MAANTHUI  MGEMOMV  MGEMLEEF  MOSHOOFD  MGODRK  MGODPR  MGODOV  \\\n",
       "0       33         1        3         2         8       0       5       1   \n",
       "1       37         1        2         2         8       1       4       1   \n",
       "2       37         1        2         2         8       0       4       2   \n",
       "\n",
       "   MGODGE  MRELGE  ...  APERSONG  AGEZONG  AWAOREG  ABRAND  AZEILPL  APLEZIER  \\\n",
       "0       3       7  ...         0        0        0       1        0         0   \n",
       "1       4       6  ...         0        0        0       1        0         0   \n",
       "2       4       3  ...         0        0        0       1        0         0   \n",
       "\n",
       "   AFIETS  AINBOED  ABYSTAND  Purchase  \n",
       "0       0        0         0        No  \n",
       "1       0        0         0        No  \n",
       "2       0        0         0        No  \n",
       "\n",
       "[3 rows x 86 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581a0956",
   "metadata": {},
   "source": [
    "#### Let's obtain some information on the target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26dbaae",
   "metadata": {},
   "source": [
    "We will try to classify whether the `Purchase` variable is a 'yes' or a 'no'. We will be checking if caravan insurances have been purchased by looking at this variable. Let us inspect this variable a little bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcce7869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['No', 'Yes'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Purchase.unique() #there are only \"Yes\" and \"No\"s "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76df3b7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     5822\n",
       "unique       2\n",
       "top         No\n",
       "freq      5474\n",
       "Name: Purchase, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Purchase'].describe() #We can see that 5,474 of the 5,822 rows have \"No\" target -- the target is quite imbalanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51d15e6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No     5474\n",
       "Yes     348\n",
       "Name: Purchase, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Purchase'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45bc14ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No     0.940227\n",
       "Yes    0.059773\n",
       "Name: Purchase, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Purchase'].value_counts(normalize = True) #so if we always say \"No\", then "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904f5239",
   "metadata": {},
   "source": [
    "#### Standardize the predictors of the dataframe only (keep the target as we want to keep the 0/1 structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55614390",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "df_scaled = pd.DataFrame(scaler.fit_transform(df.iloc[:,:-1]),columns = df.columns[:-1]) #scale the predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "533b2618",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MOSTYPE    -0.0\n",
       "MAANTHUI   -0.0\n",
       "MGEMOMV     0.0\n",
       "MGEMLEEF    0.0\n",
       "MOSHOOFD    0.0\n",
       "           ... \n",
       "AZEILPL    -0.0\n",
       "APLEZIER   -0.0\n",
       "AFIETS     -0.0\n",
       "AINBOED     0.0\n",
       "ABYSTAND   -0.0\n",
       "Length: 85, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(df_scaled.mean(),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17f7717f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MOSTYPE     1.0\n",
       "MAANTHUI    1.0\n",
       "MGEMOMV     1.0\n",
       "MGEMLEEF    1.0\n",
       "MOSHOOFD    1.0\n",
       "           ... \n",
       "AZEILPL     1.0\n",
       "APLEZIER    1.0\n",
       "AFIETS      1.0\n",
       "AINBOED     1.0\n",
       "ABYSTAND    1.0\n",
       "Length: 85, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(df_scaled.std(),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6bc959f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled[\"Purchase\"] = df.Purchase.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ce7e1c",
   "metadata": {},
   "source": [
    "Technically, scaling the whole dataframe at once is not a correct approach because we will later split it as training/test datasets. For now, this is not a big deal because here we are just showing how to use KNN. However, in the future, this will be a problem. The reason is, we are peaking ahead to the test data by using it to scale the data. So, indirectly, the test set plays a role in the training steps if we scale the whole dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c59f82",
   "metadata": {},
   "source": [
    "#### Let us create the dataframe with predictors and only the target and then sample 20% of the dataset as a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f84c6a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df_scaled, test_size=0.2) #test_size 0.2 means 20% of the dataset will be sampled\n",
    "#train.shape[0] + test.shape[0] == df.shape[0] #should be true! (why?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dab3671c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(columns=\"Purchase\") #drop the purchase column\n",
    "y_train = train.Purchase #take the purchase column\n",
    "\n",
    "X_test = test.drop(columns=\"Purchase\")\n",
    "y_test = test.Purchase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4dd12db",
   "metadata": {},
   "source": [
    "#### Now we are ready to fit a KNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bfc1aaea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neigh = KNeighborsClassifier(n_neighbors=1) #train a KNN with K = 1\n",
    "neigh.fit(X_train, y_train) #fit it to our training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc3af9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = neigh.predict(X_test) #predict the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f0368da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1019,   73],\n",
       "       [  64,    9]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_1 = confusion_matrix(y_test, y_pred)#first row of the confusion matrix will be the true \"No\"s and second row \"Yes\"s\n",
    "cm_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2539c499",
   "metadata": {},
   "source": [
    "#### Let us write a function that takes the \"K\" value and returns all the statistics that we are interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "de82ac4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_stats(k, X_train, y_train, X_test, y_test):\n",
    "    neigh = KNeighborsClassifier(n_neighbors=k) #train a KNN with K = 1\n",
    "    neigh.fit(X_train, y_train) #fit it to our training set\n",
    "    y_pred = neigh.predict(X_test) #predict the test set\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    nr_pos = np.sum(y_pred == \"Yes\")\n",
    "    true_neg = cm[0][0]\n",
    "    true_pos = cm[1][1]\n",
    "    false_pos = cm[0][1]\n",
    "    false_neg = cm[1][0]\n",
    "    misclassification_rate = (false_pos + false_neg)/np.sum(cm)\n",
    "    precision = true_pos / (true_pos + false_pos) #out of all times we say positives what percent we are accurate\n",
    "    sensitivity = true_pos / (true_pos + false_neg) #or recall (out of positives what percent can we guess)\n",
    "    return nr_pos, true_pos, misclassification_rate, precision, sensitivity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55406ec7",
   "metadata": {},
   "source": [
    "#### Question: Deliverable on KNN method\n",
    "Use the `k_stats` function in a for loop and report the results obtained by the KNN method for $K=1,3,5,7,9$. To this end, create a pandas dataframe with columns `K`, `number pos`, `true pos`, `misclassification`, `precision`, `sensitivity`. Analyze the misclassification vs. sensitivity tradeoff with respect to increasing $K$. Compare your results with the classifier which always says \"No\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f16e782",
   "metadata": {},
   "source": [
    "#### Answer: We construct a dataframe which includes the \"K\" hyperparameter and the test statistics KNN with this K achieves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "771e964c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_knn = pd.DataFrame(columns=['K','number pos', 'true pos', 'misclassification','precision','sensitivity'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f86222",
   "metadata": {},
   "source": [
    "Here the first column is the \"K\" value we use. The second column, `number pos`, is the number of times our method says \"Yes\" for a test instance. `true pos` is the number of times these are indeed \"Yes\" instances (true positive classification). Moreover, we give the misclassification rate, precision, and senstivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4d231b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(5):\n",
    "    nr_pos, true_pos, mc, pre, sens = k_stats(2*k+1, X_train, y_train, X_test, y_test)\n",
    "    df_knn.loc[k] = [2*k+1,nr_pos, true_pos, mc, pre, sens]\n",
    "df_knn[\"K\"] = pd.to_numeric(df_knn.K, downcast='integer')\n",
    "df_knn[\"number pos\"] = pd.to_numeric(df_knn[\"number pos\"], downcast='integer')\n",
    "df_knn[\"true pos\"] = pd.to_numeric(df_knn[\"true pos\"], downcast='integer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ca9adf51",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_40e71_\" ><thead>    <tr>        <th class=\"col_heading level0 col0\" >K</th>        <th class=\"col_heading level0 col1\" >number pos</th>        <th class=\"col_heading level0 col2\" >true pos</th>        <th class=\"col_heading level0 col3\" >misclassification</th>        <th class=\"col_heading level0 col4\" >precision</th>        <th class=\"col_heading level0 col5\" >sensitivity</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                                <td id=\"T_40e71_row0_col0\" class=\"data row0 col0\" >1</td>\n",
       "                        <td id=\"T_40e71_row0_col1\" class=\"data row0 col1\" >82</td>\n",
       "                        <td id=\"T_40e71_row0_col2\" class=\"data row0 col2\" >9</td>\n",
       "                        <td id=\"T_40e71_row0_col3\" class=\"data row0 col3\" >0.117597</td>\n",
       "                        <td id=\"T_40e71_row0_col4\" class=\"data row0 col4\" >0.109756</td>\n",
       "                        <td id=\"T_40e71_row0_col5\" class=\"data row0 col5\" >0.123288</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_40e71_row1_col0\" class=\"data row1 col0\" >3</td>\n",
       "                        <td id=\"T_40e71_row1_col1\" class=\"data row1 col1\" >37</td>\n",
       "                        <td id=\"T_40e71_row1_col2\" class=\"data row1 col2\" >7</td>\n",
       "                        <td id=\"T_40e71_row1_col3\" class=\"data row1 col3\" >0.082403</td>\n",
       "                        <td id=\"T_40e71_row1_col4\" class=\"data row1 col4\" >0.189189</td>\n",
       "                        <td id=\"T_40e71_row1_col5\" class=\"data row1 col5\" >0.095890</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_40e71_row2_col0\" class=\"data row2 col0\" >5</td>\n",
       "                        <td id=\"T_40e71_row2_col1\" class=\"data row2 col1\" >7</td>\n",
       "                        <td id=\"T_40e71_row2_col2\" class=\"data row2 col2\" >3</td>\n",
       "                        <td id=\"T_40e71_row2_col3\" class=\"data row2 col3\" >0.063519</td>\n",
       "                        <td id=\"T_40e71_row2_col4\" class=\"data row2 col4\" >0.428571</td>\n",
       "                        <td id=\"T_40e71_row2_col5\" class=\"data row2 col5\" >0.041096</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_40e71_row3_col0\" class=\"data row3 col0\" >7</td>\n",
       "                        <td id=\"T_40e71_row3_col1\" class=\"data row3 col1\" >3</td>\n",
       "                        <td id=\"T_40e71_row3_col2\" class=\"data row3 col2\" >1</td>\n",
       "                        <td id=\"T_40e71_row3_col3\" class=\"data row3 col3\" >0.063519</td>\n",
       "                        <td id=\"T_40e71_row3_col4\" class=\"data row3 col4\" >0.333333</td>\n",
       "                        <td id=\"T_40e71_row3_col5\" class=\"data row3 col5\" >0.013699</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_40e71_row4_col0\" class=\"data row4 col0\" >9</td>\n",
       "                        <td id=\"T_40e71_row4_col1\" class=\"data row4 col1\" >2</td>\n",
       "                        <td id=\"T_40e71_row4_col2\" class=\"data row4 col2\" >1</td>\n",
       "                        <td id=\"T_40e71_row4_col3\" class=\"data row4 col3\" >0.062661</td>\n",
       "                        <td id=\"T_40e71_row4_col4\" class=\"data row4 col4\" >0.500000</td>\n",
       "                        <td id=\"T_40e71_row4_col5\" class=\"data row4 col5\" >0.013699</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fc670e32970>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_knn.style.hide_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad893f39",
   "metadata": {},
   "source": [
    "Here, we can see that the more \"K\" we pick, the more misclassification error we get. However, see the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "017f27d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No     0.937339\n",
       "Yes    0.062661\n",
       "Name: Purchase, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e469b4",
   "metadata": {},
   "source": [
    "Here we can see that even if we say \"No\" all the time, our misclassification rate will be already $6.6 \\%$. So, the fact that having a lower misclassification rate when we increase $K$ is not very surprising, as we can observe from `df_knn` that the larger $K$ gets the less we predict \"Yes\". So misclassification should not be our main metric here. We might for example be interested in $K=3$ where we still have an $8.2 \\%$ misclassification rate, but we still find $7$ of the positives compared to $1$ positive in the case of $K=9$. This is a decision where managerial insights will play a role."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
